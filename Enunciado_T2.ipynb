{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393/578 Máquinas de Aprendizaje - 2019-1 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 2  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Manipulaciones básicas en numpy\n",
    "* Preprocesamiento y exploración de datos, creación de datos sinteticos\n",
    "* Regresión Lineal Regularizada: _Ridge_ y _Lasso_\n",
    "* SVM\n",
    "* Nociones de clases desbalanceadas\n",
    "* Más _Cross Validation_\n",
    "\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
    "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos). Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
    "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
    "* Formato de entrega: envı́o de link del repositorio en _Github_ (en caso de ser repositorio privado, invitar como colaborador al usuario de github \"avalderr\") al correo electrónico del ayudante (*<alvaro.valderrama.13@sansano.usm.cl>*), en copia al profesor (*<cvalle@inf.utfsm.cl>*). Especificar el siguiente asunto: [INF393/578-2019 Tarea2]\n",
    "* Fecha de entrega y presentaciones: 31 de Mayo. Hora límite de entrega: 23:00. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail. \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en tres partes:\n",
    "\n",
    "[1.](#primero) Clasificación de datos no-linealmente separable  \n",
    "[2.](#segundo) Clasificación con clases desbalanceadas    \n",
    "[3.](#tercero) Regularización para regresión   \n",
    "\n",
    "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo solo son guias y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes seran valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
    "Recuerden intercalar su código con comentarios y con celdas _Markdown_ con los comentarios de la pregunta y con cualquier analisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. \n",
    "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará mucho la elección en si, en cambio la argumentación detrás de la elección será lo más ponderado.\n",
    "Si algun modelo se demora demasiado en correr en su maquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, esto puede ser relevante para las maquinas más lentas al momento de realizar exploraciones con _K-folds_ por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Clasificación de datos no-linealmente separables\n",
    "\n",
    "Algunos modelos de clasificación buscan implicita o explicitamente separar los datos linealmente, es decir ajustar un hiperplano que separe en 2 subespacios el espacio de las variables, separando ambas clases del _target_. Sin embargo en la mayoría de los casos reales esto resulta imposible. Sin embargo esto no significa que no podamos ajustar modelos con estos datos o buscar transformaciones que nos permitan utilizarlos. \n",
    "    \n",
    "![Alt Text](http://people.cs.uchicago.edu/~dinoj/manifold/swissroll.gif) \n",
    "\n",
    "[comment]: <> (Swiss Roll)\n",
    "\n",
    "En esta primera parte de la tarea crearemos manualmente un set de datos categóricos no linealmente separables. Este se conformará de puntos en $\\mathbb{R}^2$, pertenecientes a una de dos categorías etiquetadas 0 o 1, los cuales se encuentran \"anidados\". Probaremos distintas aproximaciones lineales y no lineales y compararemos sus desempeños.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Creando los datos\n",
    "La función `do_circles` retorna un conjunto de puntos etiquetados, donde la etiqueta 0 corresponde a puntos siguiendo una circunferencia (con un ruido asociado) y la etiqueta 1 a puntos dentro de esa circunferencia.\n",
    "\n",
    "Los parametros de esta función tienen nombres intencionalmente no descriptivos. Analise la función y comente interpretación puede darle a cada uno de los parámetros con respecto a la influencia que tendrán en el set de datos obtenidos. Si lo estima conveniente, cambie el nombre de los parámetros a nombres más descriptivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_circles(n_dots = 3000, ns = 0.15, scr = 0.3, cf = 1):\n",
    "    generator = check_random_state(42)\n",
    "    \n",
    "    linspace = np.linspace(0, 2*cf*np.pi, n_dots)\n",
    "    circle_x = np.cos(linspace)\n",
    "    circle_y = np.sin(linspace)\n",
    "\n",
    "    inner_circle_x, outer_circle_x, inner_circle_y, outer_circle_y = train_test_split(circle_x, circle_y, test_size = 0.5)\n",
    "    inner_circle_x , inner_circle_y = inner_circle_x*scr , inner_circle_y*scr \n",
    "\n",
    "    X = np.vstack((\n",
    "        np.append(outer_circle_x, inner_circle_x),\n",
    "        np.append(outer_circle_y, inner_circle_y)\n",
    "    )).T\n",
    "\n",
    "    y = np.hstack([\n",
    "        np.zeros(n_dots // 2, dtype=np.intp),\n",
    "        np.ones(n_dots // 2, dtype=np.intp)\n",
    "    ])\n",
    "\n",
    "    X += generator.normal(scale = ns, size = X.shape)\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Graficar los datos\n",
    "Cree una función que grafíque los datos, coloreando distintamente los puntos de cada clase. \n",
    "Utilice esta función para verificar gráficamente lo que propuso en la pregunta anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circles( . . . . ):\n",
    "    # . . . \n",
    "    fig1 = fig.add_subplot(121)\n",
    "    fig1.scatter(X_train[y_train==0][:,0], X_train[y_train==0][:,1])\n",
    "    # . . . \n",
    "    fig1.set_title(\"Train Set\")\n",
    "    # . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c Regresión Logística\n",
    "\n",
    "Realice una regresión logistica para a lo menos 5000 puntos generados con los siguientes parámetros:\n",
    "* `do_circles(n_dots, 0.2, 0.3, 1)`\n",
    "* `do_circles(n_dots, 0, 0.3, 1)`\n",
    "\n",
    "Grafique los datos que está ajustando y calcule el _score_ del regresor logístico en cada caso.\n",
    "Qué valor entrega el _score_ del regresor logístico? Le parece un buen desempeño para la tarea a realizar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.d Graficos\n",
    "Para entender mejor lo que está ocurriendo con el clasificador en cada uno de los casos, grafícaremos los datos clasificados y la frontera de desición ajustada por el modelo. Para esto complete la función siguiente y luego utilicela para ambos modelos y conjuntos de datos ajustados en la pregunta anterior. \n",
    "\n",
    "Que puede concluir luego de estas visualizaciones? Es posible mejorar el desempeño de algun clasificador lineal sin hacer una transformación no lineal de los datos? Que ocurre con el clasificador si disminuimos el ruido, mejora realmente su desempeño? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier(classifier, X_train, Y_train, X_test, Y_test, train_or_test='test'):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    axis = plt.axes()\n",
    "    if tr_tst == 'train':\n",
    "        # Scatter train points (axis.scatter(. . .)) \n",
    "    elif tr_tst == 'test':\n",
    "        # Scatter test points\n",
    "    XX, YY = np.mgrid[-2:2:200j, -2:2:200j] # grid for cassifier\n",
    "    Z = clf.predict(np.c_[XX.ravel(), YY.ravel()]) # what the classifier predicts over the space\n",
    "    Z = Z.reshape(XX.shape) # for consistency\n",
    "    Zplot = Z > 0.5 # to separate both classes\n",
    "    axis.pcolormesh(XX, YY, Zplot, cmap='YlGn')\n",
    "    axis.contour(XX, YY, Zplot, alpha=1, colors=[\"r\"], linestyles=[\"-\"], levels=[0.5])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las siguientes preguntas nos enfocaremos en la **solo en la versión con ruido de los datos** pues en la práctica no existen datos sin ruido. Probaremos algunos métodos no lineales para ver que tanto logramos mejorar el desempeño en nuestros datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.e SVM\n",
    "\n",
    "Entrene un clasificador SVM con los datos con ruido. Qué forma tiene la frontera de desición esta vez? \n",
    "\n",
    "Mejoran los resultados al alejarse de los metodos puramente lineales? Comente sobre el desempeño del modelo y su sensibilidad a los parámetros `C` y `gamma`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SV = SVC(C=1, gamma=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.f KNN\n",
    "Pruebe ahora con otro método no linal, _K nearest neighbors_ o KNN. Discuta sus resultados y la frontera de desición que encuentra el modelo. \n",
    "\n",
    "Realice un _Cross Validation_ sobre el parámetro `n_neighbors` o `p` (o ambos usando un mallado) y comente si mejoran significativamente los resultados. Puede apoyarse de los códigos de la tarea 1 para realizar el _Cross Validation_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=5, p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.g\n",
    "Del mejor modelo obtenido en el punto anterior, grafíque los datos de test coloreando de manera difente los puntos mal clasificados por su modelo. Por qué el modelo no logra clasificar bien estos puntos? Qué habría ocurrido si estuvieramos utilizando los datos sin ruido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it yourself c:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.h Metodo Kernel\n",
    "Utilizaremos Kernel Gaussiano para preprocesar los datos, pasando implícitamente por un espacio altamente dimensional (más especificamente por un _manifold_ de un espacio infinito dimensional), obteniendo una representación lo más linealmente separable posible. \n",
    "\n",
    "Ajuste el kernel y transforme los datos. Grafique los puntos transformados y comente que realiza el modelo. Varie luego el valor de `gamma` para tratar de entender qué influencia tiene sobre la separabilidad de los puntos transformados. Le parece un buen método para este problema? \n",
    "\n",
    "Usando algún valor de `gamma` que le parezca adecuado, ajuste un modelo de regresión logística sobre los datos transformados. Mejora el desempeño del modelo respecto a la versión original? Se logra aumentar la separabilidad lineal de los datos efectivamente? Apoyese de gráficos y métricas adecuados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "ker = KernelPCA(2,kernel='rbf',gamma=5)\n",
    "ker.fit(X_train)\n",
    "X_ker_train = ker.transform(X_train)\n",
    "# . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.i Manualmente\n",
    "Como nosotros conocemos como se generaron los datos tenemos una ventaja sobre los modelos. Genere una transformación de los datos que estime conveniente para obtener datos linealmente separables. Puede aumentar o disminuir la dimensión a gusto, por ejemplo puede realizar algo del estilo $(x,y)\\longrightarrow (x+y)$, ó $(x,y)\\longrightarrow (x,y,x+y,x-y)$. Apoyese de las carácteristicas geométricas del conjunto de datos y justifique sus elecciónes con gráficos adecuados. \n",
    "\n",
    "Luego entrene un regresor logístico sobre sus datos transformados y comente sobre la utilidad de conocer cómo se generaron los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Clasificación con clases desbalanceadas\n",
    "\n",
    "En las tareas de clasificación supervisada, buscamos que mediante los ejemplos etiquetados la maquina pueda aprender los atributos inerentes a las distintas clases. Sin embargo, en muchos casos reales de clasificación, la cantidad de ejemplos de cada clase son muy dispares, en cuyo caso hablamos de clases desbalanceadas. Si uno no aplica estrategias para compensar este problema, la maquina aprenderá muy bien las caracteristicas de la clase más representada pero no logrará extraer información generalizable de la clase menos representada. Además, debemos tener cuidado al momento de interpretar las distintas métricas a las cuales tenemos acceso, pues debemos tomar en cuenta el balance de las clases y la naturaleza del problema para evaluar realmente que tan bueno es el desempeño. \n",
    "\n",
    "<img src=\"http://tynmedia.com/tynmag/wp-content/uploads/sites/3/2018/10/fraude.jpg\"  style=\"height:3cm;\"  />\n",
    "\n",
    "Para esta parte de la tarea utilizaremos el siguiente _dataset_ publicado en Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud. Este conjunto de datos contiene unos 285000 ejemplos de transacciones con tarjetas de credito reales, realizadas en 2013 por clientes europeos. Los datos son totalemente anónimos y son el resultado de un PCA a partir de los datos originales excepto por la columna `Time` con el tiempo en segundos desde la primera transacción, `Amount` con el monto de la transacción y `Class` que indica si la transacción es fraudulenta o no. La tarea en cuestión consiste en lograr predecir cuando una transacción es fraudulenta o no automaticamente, para así poder detenerla antes de que se termine. Sin embargo, por la naturaleza de las transacciones bancarias, este probleme es desbalanceado, de hecho de los 285000 transacciones registradas, solo 492 son fraudulentas! A lo largo de esta pregunta pondremos en evidencia los problemas que se originan de este desbalance de clases y trataremos de dar luces a algunas herramientas que nos permitan sortear esos problemas y como medir realmente el desempeño en esta clase de problemas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Carga de datos\n",
    "Descargue los datos y carguelos usando pandas. Haga una exploración rápida de los datos, cuantos datos hay, como se reptarten sus valores.\n",
    "\n",
    "Grafique la matriz de correlación, a primera vista parece relevante mantener la columna `Time`? En su opinión, conociendo la naturaleza del problema le parece relevante esa información para predecir el _target_?\n",
    "\n",
    "Cuantos ejemplos hay de cada clase? Son las clases desbalanceadas efectivamente? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# . . . \n",
    "\n",
    "plt.imshow(df.corr())\n",
    "\n",
    "# . . .\n",
    "\n",
    "df.loc[lambda x: x.Class != 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b Ligero preprocesamiento\n",
    "\n",
    "Escale la columna `Amount`. Por qué es aconsejable realizar esto? Le parece necesario realizarlo en el resto de las columnas? \n",
    "\n",
    "Separe los atributos del _target_.\n",
    "\n",
    "Separe luego los datos en _Training set_ y _Validation set_, con un 20% de los datos como validación y el resto como _train_. Asegurese que se mantienen las proporciones de ejemplos de cada clase en ambos sets. \n",
    "\n",
    "Qué ocurriria si por ejemplo todos los ejemplos de la clase 1 quedaran en el _validation set_, que haría cualquier máquina de aprendizaje al aprender solo con la clase 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# . . .\n",
    "\n",
    "df['Amount'] = scaler.transform(df['Amount'].values.reshape(-1,1))\n",
    "\n",
    "x = df[df.columns[1:-2]]\n",
    "y = df.Class\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c Regresor logístico\n",
    "\n",
    "Entrene un regresor logístico con los datos obtenidos de la pregunta anterior y calcule su desempeño (_score_ por ahora) sobre los datos de validación. A priori le parece un buen desempeño? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# . . . \n",
    "# . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.d _Always_ 0\n",
    "\n",
    "Suponga un modelo le entrega como resultado en el conjunto de validación el siguiente `y_pred`. Qué está haciendo este predictor? Que _score_ obtendría tal modelo sobre el conjunto de validación? Le parece que el modelo tenga un buen desempeño? Concluya sobre la calidad del _accuracy_ que obtenemos con `.score` para evaluar el desempeño de estos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.np.zeros(y_val.shape)\n",
    "\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.e Matriz de confución\n",
    "\n",
    "Investigue un poco sobre los valores que conforman la matriz de confución o _confusion matrix_. Comente sobre la significancia de los distintos valores para el problema en cuestión. \n",
    "\n",
    "Escriba una función que a partir de un modelo o de los valores predecidos por un modelo, grafique la matriz de confución. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede usar libreria seaborn para realizar facilmente heatmaps anotados: \n",
    "import seaborn as sns\n",
    "# . . .\n",
    "sns.heatmap( confusion_matrix(y_test, model.predict(X_test))/len(X_test),cmap='winter', annot=True)    \n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafique la matriz de confución para la regresión logística realizada en el punto c y para los valores `y_pred` del punto d. Le parecen parecidos ahora ambos modelos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.f Curva ROC\n",
    "La curva ROC tiene bastante utilidad para evaluar la calidad de distintos modelos en estos casos. Investigue un poco sobre su significado para poder interpretarla correctamente y luego escriba una función que reciba un modelo entrenado y la grafíque. \n",
    "\n",
    "Note que `sklearn` trae implementado una función que entrega los puntos de la curva ROC, note eso sí que debe entregarle las probabilidades usando el método `predict_proba` del modelo entrenado. \n",
    "\n",
    "Para evaluar distintos modelos utilizará bastante las curvas ROC y la matriz de confución, por lo que sería recomendable escribir una función que reciba un modelo y datos y realice tanto la curva ROC como la matriz de confución, aunque escribir tal funcion no es requisito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_ts, model.predict_proba(x_ts)[:,1],pos_label=1)\n",
    "\n",
    "plt.plot(fpr, tpr, label=# . . . )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función definida para su modelo de regresión logística. Comente el gráfico obtenido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.g _Undersampling_\n",
    "\n",
    "Considerando que la gran mayoría del aprendizaje se realiza en los ejemplos no fraudulentos, una aproximación para tratar de mejorar el desempeño de los modelos entrenados es simplemente reducir la cantidad de ejemplos de una clase para obtener nuevos conjuntos de datos con clases más balanceadas. Así, el aprendizaje se realiza de manera más balanceada entre ambas clases y se logran extraer mejor los atributos de cada clase. \n",
    "\n",
    "Complete la siguiente función para que realice un _undersampling_ de la clase 0 para obtener una proporción en el nuevo conjundo de datos de `times` veces el numero de transacciónes normales frente a fraudulentas. Comente sobre la decición del parametro `replace` de la función `numpy.random.replace`. \n",
    "\n",
    "\n",
    "Note que la función recibe el _DataFrame_ con todos los datos. Se pide que retorne los con juntos de _train_ y _validation_ para luego poder entrenar un modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(df, times = 10, validation_ratio = 0.2):\n",
    "    fraud_indices = pd.np.array(df[df.Class==1].index)\n",
    "    normal_indices = # . . .\n",
    "\n",
    "    Count_Fraud_transacation = # . . .\n",
    "    \n",
    "    Normal_indices_undersample = pd.np.array(\n",
    "    pd.np.random.choice(\n",
    "        # wich indices . . . ,\n",
    "        Count_Fraud_transacation * #something,\n",
    "        replace = # True or False?)\n",
    "    )\n",
    "    \n",
    "    undersample_data = pd.np.concatenate([fraud_indices,Normal_indices_undersample])\n",
    "    undersample_data = df.iloc[undersample_data]\n",
    "    \n",
    "    # . . . X, y\n",
    "    # train test split\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.h Entrenar con _Undersampling_\n",
    "\n",
    "Pruebe distintos valores para el parámetro `times` y evalue si hay diferencias significativas en la curva ROC y la matriz de confución. Evidentemente el número de ejemplos cambia a medida cambia el parámetro `times`, por lo que la matriz de confusión debe dividirla por la cantidad de datos considerados para realizar comparaciones justas, de proporciones de ejemplos clasificados y no de número de ejemplos. \n",
    "\n",
    "Como se comparan estos modelos con el modelo de regresión logística con todos los datos? Ve alguna ventaja en el uso de _undersampling_ frente al uso de todos los datos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.i SVM\n",
    "Las SVM son una herramienta muy poderosa pero comparativamente costosa (frente a la regresión lineal por ejemplo). Entrenar una SVM con todos los datos lleva un tiempo considerablemente mayor que lo que se han demorado nuestros modelos hasta ahora, todo ese tiempo si si quiera saber si la SVM se adapta bien a este problema o no! Una ventaja de _undersample_ es precisamente que tenemos menos datos, con lo que podemos probar rápidamente muchos modelos antes de enfocarnos en detalle en uno. \n",
    "\n",
    "Entrene una SVM usando _undersampling_ y compare con el desempeño de este modelo frente a un regresor logístico en las mismas condiciones. Vale la pena considerar SVM? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.j _Oversampling_\n",
    "\n",
    "Otra aproximación para resolver el problema de las clases desbalanceadas es hacer _oversampling_. A partir de una muestra relativamente pequeña de ejemplos, en este caso de los casos de fraude, se busca crear un conjunto de datos más grande similar al inicial, que permita al modelo aprender las caracteristicas de esa clase, buscando nuevamente obtener clases más balanceadas que originalmente, pero esta vez sin reducir la cantidad de ejemplos. Esta aproximación tiene la ventaja que no reduce la cantidad de ejemplos pero trae la complicación de decidir cómo se van a crear los datos nuevos.\n",
    "\n",
    "Dos aproximaciones bastante estandar son SMOTE y ADASYN. Investigue un poco que hace SMOTE y que diferencia implemente ADASYN. Por qué cree puede ser deseable buscar que los datos sintéticos no sean linealmente dependientes de los datos originales? \n",
    "\n",
    "Elija alguno de los dos métodos e impelementelo con el modelo de regresión logística. Comente sobre el desempeño de tal modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "ada = ADASYN()\n",
    "x_tr_r, y_tr_r  = smo.fit_resample(x_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que tanto SMOTE como ADASYN tienen muchos parámetros que podrían afectar la calidad de los datos generados. No se requiere que elijan tales parametros (los por defecto bastan), pero se valorará un pequeño comentario sobre los parámetros de los métodos y qué representan en la heuristica utilizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Regularización para regresión. \n",
    "\n",
    "Un problema que podemos encontrar transversalmente a todos los modelos es el problema del _overfitting_. Este problema consiste en un modelo que aprende demasiado bien los datos de ejemplo o entrenamiento, al punto que al momento de ver ejemplos desconocidos o de validación, baja su desempeño respecto a un modelo \"menos entrenado\". En algunos casos podriamos decir que el modelo \"aprende de memoria\" los ejemplos, en vez de intentar obtener información generalizable a partir de su entrenamiento. Para el caso de la regresión, una de las aproximaciones más comunes para tratar de mitigar este efecto es el de la regularización. Agregando una penalización a la norma de los parametros de la regresión podemos restringir la eficiencia del modelo al momento de aprender los datos de entrenamiento, incluso forzando dependiendo de la intensidad de la regularización que algunos parametros se vuelvan cero. \n",
    "\n",
    "<img src=\"https://pngimage.net/wp-content/uploads/2018/06/house-for-sale-sign-png-6.png\"  style=\"height:13.9cm;\"  />\n",
    "\n",
    "En esta pregunta utilizaremos nuevamente la base de datos de precios de casas en King County, https://www.kaggle.com/harlfoxem/housesalesprediction, que utilizamos en la pregunta 1. Utilizaremos estos datos ya conocidos y analizados anteriormente para enfocarnos en la regularización para regresión. Exploraremos como varian los distintos errores de predicción y como cambian los valores de los parámetros ajustados por el modelo para distintos valores del coeficiente de regularización, para tratar de entender que ocurre con las distintas regularizaciones y sus diferencias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a Carga y preprocesamiento.\n",
    "Cargue y preprocese los datos de la misma forma en que lo realizó en la tarea 1. Puede reciclar sus códigos y agregar modificaciones que le parezcan pertinentes. Para esta parte utilize 0.5 de los datos como _training set_, 0.3 como _validation set_ y 0.2 como _test set_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.b Modelo sin regularización\n",
    "Entrene un modelo de regresión lineal no regularizado con los datos preprocesados. Calcule el error cuadrático medio (MSE) del modelo para el conjunto de validación y el de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(# . . . )\n",
    "    \n",
    "mse = ((reg.predict(x_val)-y_val)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.c Regularización\n",
    "Discuta brevemente que busca realizar (en terminos del ajuste de los parámetros del modelo de regresión lineal) la regularización de _Lasso_. Por qué se habla de penalización en norma $L^1$? Apoyese de ecuaciones. Qué importancia tiene el parámetro de regularización $\\lambda$? \n",
    "\n",
    "Qué diferencia hay entre _Lasso_ y _Ridge_? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.d Influencia sobre el error\n",
    "Grafique como varia el error de entrenamiento y el error de validación a medida se cambia el valor del parámetro $\\lambda$. Para esto debe entrenar un modelo para cada uno de los parámetros que considerará en el gráfico y calcular el MSE para ambos sets. Comente sobre lo que ve en el gráfico y si lo encuentra pertinente puede calcular en más detalle alguna zona que le parezca interesante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example:\n",
    "MSE_list = []\n",
    "space = pd.np.logspace(-2,1,50)\n",
    "for lambd in space:\n",
    "    model = Lasso(alpha=lambd)\n",
    "    # fit, error...\n",
    "# . . . \n",
    "# plt.plot( space, MSE_list, . . . ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.e Influencia sobre los coeficientes\n",
    "Grafique ahora como se comporta el valor de los coeficientes del modelo lineal en el modelo entrenado a medida crece $\\lambda$, tanto para _Lasso_ como para _Ridge_. Para esto entrene un modelo para cada valor de $\\lambda$ y guarde sus coeficientes, como propone el princio de código a continuación. \n",
    "\n",
    "Qué diferencias ve entre _Ridge_ y _Lasso_? Coincide este comportamiento con lo que esperaría teóricamente de cada uno de los modelos? \n",
    "\n",
    "Podemos utilizar estos gráficos para discutir sobre la cantidad de información que entrega cada uno de los atributos para predecir el _target_? Cual de ambos (_Ridge_ o _Lasso_) le parece mejor para este tipo de discución? Compare lo que muestran estos gráficos con alguna otra aproximación para medir la significancia de cada atributo (como correlación o _mutual information_ por ejemplo) y discuta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = pd.np.linspace(0.0001,3,100)\n",
    "coefs = []\n",
    "for l in space:\n",
    "    model = # . . .\n",
    "    \n",
    "    # . . .\n",
    "    \n",
    "    coefs.append(model.coef_)\n",
    "\n",
    "for y_arr, label in zip(pd.np.squeeze(coefs).T, x_cols):\n",
    "    plt.plot(space, y_arr, label=label)\n",
    "    # . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.f K-_fold_ sobre $\\lambda$\n",
    "Realice 5-_fold_ o 10-_fold_ sobre el parámetro de regularización $\\lambda$, ya sea para _Lasso_ o _Ridge_. Explore a lo menos 20 valores distintos de $\\lambda$ en un intervalo relevante luego de lo aprendido en las preguntas anteriores. Utilice MSE como el error a minimizar. \n",
    "\n",
    "Compare el error de entrenamiento y de validación para este modelo respecto al modelo lineal sin regularización entrenado inicialmente. Comente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
